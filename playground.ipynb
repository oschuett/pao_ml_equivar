{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import itertools\n",
    "from pao_file_utils import parse_pao_file\n",
    "from sympy.physics.quantum.cg import CG\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/cp2k/cp2k/blob/master/src/common/spherical_harmonics.F\n",
    "def Y_l(r, l):\n",
    "    \"\"\"Real Spherical Harmonics\"\"\"\n",
    "    assert r.shape[-1] == 3\n",
    "\n",
    "    if l < 0:\n",
    "        raise Exceptoin(\"Negative l value\")\n",
    "    elif l == 0:\n",
    "        return np.sqrt(1.0 / (4.0 * np.pi))\n",
    "    elif l == 1:\n",
    "        pf = np.sqrt(3.0 / (4.0 * np.pi))\n",
    "        return pf * r\n",
    "    elif l == 2:\n",
    "        x = r[..., 0]\n",
    "        y = r[..., 1]\n",
    "        z = r[..., 2]\n",
    "        result = np.zeros(5)\n",
    "        # m = 2\n",
    "        pf = np.sqrt(15.0 / (16.0 * np.pi))\n",
    "        result[0] = pf * x**2 - y**2\n",
    "        # m = 1\n",
    "        pf = np.sqrt(15.0 / (4.0 * np.pi))\n",
    "        result[1] = pf * z * x\n",
    "        # m = 0\n",
    "        pf = np.sqrt(5.0 / (16.0 * np.pi))\n",
    "        result[2] = pf * (3.0 * z**2 - 1.0)\n",
    "        # m = -1\n",
    "        pf = np.sqrt(15.0 / (4.0 * np.pi))\n",
    "        result[3] = pf * z * y\n",
    "        # m = -2\n",
    "        pf = np.sqrt(15.0 / (16.0 * np.pi))\n",
    "        result[4] = pf * 2.0 * x * y\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolute(coords, kinds, central_atom, max_l):\n",
    "    natoms = coords.shape[0]\n",
    "    assert coords.shape[1] == 3\n",
    "\n",
    "    integrals = []\n",
    "    for l in range(max_l + 1):\n",
    "        for sigma in [0.5, 1.0, 2.0, 3.0, 4.0]:\n",
    "            for ikind in sorted(kinds):\n",
    "                integrals.append(np.zeros(2*l + 1))\n",
    "                for iatom in range(natoms):\n",
    "                    if atom2kind[iatom] == ikind and iatom != central_atom:\n",
    "                        r = coords[central_atom] - coords[iatom]\n",
    "                        angular_part = Y_l(r, l)\n",
    "                        radial_part = np.exp(- np.dot(r,r) / sigma**2)\n",
    "                        integrals[-1] += radial_part * angular_part\n",
    "    return integrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_cache = dict()\n",
    "\n",
    "def get_clebsch_gordan_coefficients(li, lj, lo):\n",
    "    global cg_cache\n",
    "    key = (li, lj, lo)\n",
    "    if key not in cg_cache:\n",
    "        assert abs(li-lj) <= lo <= abs(li+lj)\n",
    "        coeffs = np.zeros(shape=(2*li+1, 2*lj+1, 2*lo+1))\n",
    "        for mi in range(-li, li+1):\n",
    "            for mj in range(-lj, lj+1):\n",
    "                for mo in range(-lo, lo+1):\n",
    "                    # https://docs.sympy.org/latest/modules/physics/quantum/cg.html\n",
    "                    cg = CG(li, mi, lj, mj, lo, mo).doit()\n",
    "                    coeffs[mi+li, mj+lj, mo+lo] = cg\n",
    "        cg_cache[key] = coeffs\n",
    "    return cg_cache[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(channels, max_l):\n",
    "    \"\"\" returns all possbile combinations of input channels up to given max_l \"\"\"\n",
    "    output_channels = list()\n",
    "    for channel_i, channel_j in itertools.combinations_with_replacement(channels, 2):\n",
    "        assert len(channel_i.shape) == len(channel_j.shape) == 1\n",
    "        li = (channel_i.size - 1) // 2\n",
    "        lj = (channel_j.size - 1) // 2\n",
    "        # There li + lj possible ways to combine the two channels.\n",
    "        # We do all of them up to a max_l.\n",
    "        lo_min = abs(li-lj)\n",
    "        lo_max = min(li+lj, max_l)\n",
    "        for lo in range(lo_min, lo_max + 1): # l of output\n",
    "            channel_o = np.zeros(2*lo+1)\n",
    "            cg = get_clebsch_gordan_coefficients(li, lj, lo)\n",
    "            channel_o = np.einsum(\"i,j,ijo->o\", channel_i, channel_j, cg)\n",
    "            output_channels.append(channel_o)\n",
    "    return output_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data and hard code metadata.\n",
    "pao_files = sorted(glob(\"2H2O_MD/frame_*/2H2O_pao44-1_0.pao\"))\n",
    "\n",
    "prim_basis_shells = {\n",
    "    'H': [2, 1, 0], # two s-shells, one p-shell, no d-shells\n",
    "    'O': [2, 2, 1], # two s-shells, two p-shells, one d-shell\n",
    "}\n",
    "\n",
    "pao_basis_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples:  324\n",
      "s channels:  110\n",
      "p channels:  155\n",
      "samples:  162\n",
      "s channels:  165\n",
      "p channels:  310\n"
     ]
    }
   ],
   "source": [
    "class Sample:\n",
    "    def __init__(self, channels, xblock):\n",
    "        self.channels = channels\n",
    "        self.xblock = xblock\n",
    "        self.s_channels = np.stack([c for c in channels if c.size == 1])\n",
    "        self.p_channels = np.stack([c for c in channels if c.size == 3])\n",
    "        #self.d_channels = np.stack([c for c in channels if c.size == 5]) #TODO generalize\n",
    "        #self.num_channels = (len(self.s_channels), len(self.p_channels), len(self.d_channels))\n",
    "\n",
    "def build_dataset(kind_name, max_l):\n",
    "    samples = []\n",
    "    for fn in pao_files:\n",
    "        kinds, atom2kind, coords, xblocks = parse_pao_file(fn)\n",
    "        #kind_onehot = encode_kind(atom2kind)\n",
    "        natoms = coords.shape[0]\n",
    "        for iatom in range(natoms):\n",
    "            if atom2kind[iatom] == kind_name:\n",
    "                initial_channels = convolute(coords, kinds, iatom, max_l)\n",
    "                comb_channels = combinations(initial_channels, max_l)\n",
    "                sample = Sample(comb_channels, xblocks[iatom])\n",
    "                samples.append(sample)\n",
    "\n",
    "    print(\"samples: \", len(samples))\n",
    "    print(\"s channels: \", samples[0].s_channels.shape[0])\n",
    "    print(\"p channels: \", samples[0].p_channels.shape[0])\n",
    "    #print(\"d channels: \", samples[0].d_channels.shape)\n",
    "    return samples\n",
    "    \n",
    "H_dataset = build_dataset(\"H\", max_l=1)\n",
    "O_dataset = build_dataset(\"O\", max_l=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 1)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(H_dataset[0].s_channels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(first_sample, pao_basis_size, prim_basis_shells):\n",
    "    \n",
    "    # define two sets of inputs\n",
    "    s_input = keras.layers.Input(shape=first_sample.s_channels.shape)\n",
    "    p_input = keras.layers.Input(shape=first_sample.p_channels.shape)\n",
    "\n",
    "\n",
    "    p_input\n",
    "    \n",
    "    x = Dense(8)(s_input)\n",
    "    \n",
    "    model = keras.Model(inputs=[s_input, p_input], outputs=outputs, name='mnist_model')\n",
    "\n",
    "# # the first branch operates on the first input\n",
    "# x = Dense(8, activation=\"relu\")(inputA)\n",
    "# x = Dense(4, activation=\"relu\")(x)\n",
    "# x = Model(inputs=inputA, outputs=x)\n",
    " \n",
    "# # the second branch opreates on the second input\n",
    "# y = Dense(64, activation=\"relu\")(inputB)\n",
    "# y = Dense(32, activation=\"relu\")(y)\n",
    "# y = Dense(4, activation=\"relu\")(y)\n",
    "# y = Model(inputs=inputB, outputs=y)\n",
    " \n",
    "# # combine the output of the two branches\n",
    "# combined = concatenate([x.output, y.output])\n",
    " \n",
    "# # apply a FC layer and then a regression prediction on the\n",
    "# # combined outputs\n",
    "# z = Dense(2, activation=\"relu\")(combined)\n",
    "# z = Dense(1, activation=\"linear\")(z)\n",
    " \n",
    "# # our model will accept the inputs of the two branches and\n",
    "# # then output a single value\n",
    "# model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "#     output_size = pao_basis_size * (prim_basis_shells[0] * num_channels[0] +\n",
    "#                                     prim_basis_shells[1] * num_channels[1] +\n",
    "#                                     prim_basis_shells[2] * num_channels[2])\n",
    "    \n",
    "#     model = keras.Sequential()\n",
    "#     #model.add(keras.layers.Dense(10, input_shape=samples[0].inputs.shape))\n",
    "#     #model.add(keras.layers.Dense(10)) # hidden layer\n",
    "#     #model.add(keras.layers.Dense(10)) # hidden layer\n",
    "    \n",
    "#     # let's try a single layer\n",
    "#     model.add(keras.layers.Dense(output_size, input_shape=samples[0].inputs.shape))\n",
    "\n",
    "    \n",
    "#     def assemble_xblock(x):\n",
    "        \n",
    "\n",
    "# #        # add a layer that returns the concatenation\n",
    "# #         # of the positive part of the input and\n",
    "# #         # the opposite of the negative part\n",
    "\n",
    "# #         def antirectifier(x):\n",
    "# #             x -= K.mean(x, axis=1, keepdims=True)\n",
    "# #             x = K.l2_normalize(x, axis=1)\n",
    "# #             pos = K.relu(x)\n",
    "# #             neg = K.relu(-x)\n",
    "# #             return K.concatenate([pos, neg], axis=1)\n",
    "\n",
    "# #         model.add(Lambda(antirectifier))\n",
    "\n",
    "#     model.compile(optimizer='adam',\n",
    "#                   loss='binary_crossentropy',\n",
    "#                   metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "#     model.summary()\n",
    "\n",
    "H_model = build_model(H_dataset[0], pao_basis_size, prim_basis_shells['H'])\n",
    "#O_model = build_model(O_dataset[0].num_channels, pao_basis_size, prim_basis_shells['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.17002359,  0.54494166, -0.67605853, -0.53623134,  0.11146726,\n",
       "         0.22992396,  0.22856215,  0.42034036, -0.26474568,  0.25754395]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(samples[0].inputs[None,:], batch_size=1)\n",
    "#samples[0].inputs[None,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165,)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0].inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
