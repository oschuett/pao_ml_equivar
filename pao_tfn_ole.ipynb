{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pao_utils import parse_pao_file, append_samples\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import se3cnn\n",
    "import livelossplot as llp\n",
    "\n",
    "import sys, os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from se3cnn.utils import torch_default_dtype\n",
    "import se3cnn.point_utils as point_utils\n",
    "from se3cnn.non_linearities import NormSoftplus\n",
    "from se3cnn.convolution import SE3PointConvolution\n",
    "from se3cnn.blocks.point_norm_block import PointNormBlock \n",
    "from se3cnn.point_kernel import gaussian_radial_function\n",
    "from se3cnn.SO3 import torch_default_dtype\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from numpy.linalg import norm\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and parse all .pao files.\n",
    "# Each file corresponds to a molecular configuration, ie. a frame.\n",
    "# Since the system contains multiple atoms, each .pao file contains multiple samples.\n",
    "class PAODataset(object):\n",
    "    def __init__(self, kind_name):\n",
    "        self.kind_name = kind_name\n",
    "        self.sample_iatoms = []\n",
    "        self.sample_coords = []\n",
    "        self.sample_xblocks = []\n",
    "        self.sample_compl_projector = []\n",
    "        \n",
    "\n",
    "        print(\"Loading data set... \", end='')\n",
    "        #TODO split in training and test set\n",
    "        for fn in glob(\"2H2O_MD/frame_*/2H2O_pao44-1_0.pao\"):\n",
    "            kinds, atom2kind, coords, xblocks = parse_pao_file(fn)\n",
    "            for iatom, kind in enumerate(atom2kind):\n",
    "                if kind != self.kind_name:\n",
    "                    continue\n",
    "                rel_coords = coords - coords[iatom,:] # relative coordinates\n",
    "                self.sample_coords.append(rel_coords)\n",
    "                xblock_i = torch.from_numpy(xblocks[iatom])\n",
    "                self.sample_xblocks.append(xblock_i)\n",
    "                self.sample_iatoms.append(iatom)\n",
    "                \n",
    "                # orthonormalize xblock_sample's basis vectors (they deviate slightly)\n",
    "                #TODO: add a regularization term for this.\n",
    "                #\n",
    "                #https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process#Alternatives\n",
    "                V = torch.t(xblock_i)  #TODO: use torch.tensor() instead?\n",
    "                VV  = torch.matmul(torch.t(V), V)\n",
    "                #print(torch.det(VV))\n",
    "                L = torch.cholesky(VV)\n",
    "                L_inv = torch.inverse(L)\n",
    "                U = torch.matmul(V, torch.t(L_inv))\n",
    "                projector = torch.matmul(U, torch.t(U))\n",
    "                identity = torch.eye(projector.shape[0])\n",
    "                compl_projector = identity - projector\n",
    "                self.sample_compl_projector.append(compl_projector)\n",
    "            \n",
    "\n",
    "        # assuming kinds and atom2kind are the same across whole training data\n",
    "        kinds_enum = list(kinds.keys())\n",
    "        self.kinds_onehot = np.zeros((len(kinds), len(atom2kind)))\n",
    "        for iatom, kind in enumerate(atom2kind):\n",
    "            idx = kinds_enum.index(kind)\n",
    "            self.kinds_onehot[idx, iatom] = 1.0\n",
    "\n",
    "        print(\"done.\")\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # roll central atom to the front\n",
    "        iatom = self.sample_iatoms[idx]\n",
    "        rolled_kinds = np.roll(self.kinds_onehot, shift=-iatom, axis=1)\n",
    "        rolled_coords =  np.roll(self.sample_coords[idx], shift=-iatom, axis=0)  \n",
    "        return rolled_kinds, rolled_coords, idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_xblocks)\n",
    "\n",
    "#dataset = PAODataset(\"O\")\n",
    "#print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PAONet(torch.nn.Module):\n",
    "    def __init__(self, num_kinds, pao_basis_size, prim_basis_shells, num_hidden=1, num_radial=4, max_radius=2.5):\n",
    "        super().__init__()\n",
    "        self.num_kinds = num_kinds\n",
    "        self.prim_basis_shells = prim_basis_shells\n",
    "        self.pao_basis_size = pao_basis_size\n",
    "                \n",
    "        nonlinearity = lambda x: torch.log(0.5 * torch.exp(x) + 0.5)\n",
    "        sigma = max_radius / num_radial\n",
    "        radii = torch.linspace(0, max_radius, steps=num_radial, dtype=torch.float64)\n",
    "        radial_function = partial(gaussian_radial_function, sigma=2*sigma)\n",
    "        radii_args = {'radii': radii, 'radial_function': radial_function}\n",
    "        \n",
    "        # Convolutions with Norm nonlinearity layers\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        \n",
    "        # features\n",
    "        input_features = [num_kinds, 0, 0]  # L=0 for atom type as one-hot encoding\n",
    "        hidden_features = [8, 8, 8] # hidden layer with filters L=0,1,2\n",
    "        output_features = [i * pao_basis_size for i in prim_basis_shells]\n",
    "\n",
    "        # input layer\n",
    "        self.layers.append(PointNormBlock(input_features, hidden_features, activation=nonlinearity, **radii_args))\n",
    "       \n",
    "        # hidden layer\n",
    "        for _ in range(num_hidden):\n",
    "            self.layers.append(PointNormBlock(hidden_features, hidden_features, activation=nonlinearity, **radii_args))\n",
    "       \n",
    "        # output layer\n",
    "        Rs_repr = lambda features: [(m, l) for l, m in enumerate(features)]\n",
    "        self.layers.append(SE3PointConvolution(Rs_repr(hidden_features), Rs_repr(output_features), **radii_args))\n",
    "                        \n",
    "        \n",
    "    def forward(self, input, difference_mat, relative_mask=None):\n",
    "        output = input\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, difference_mat, relative_mask)\n",
    "        #TODO: things could be much simpler if the network directly returned decoded 2-D xblocks\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_xblock(xvec, num_pao, prim_basis_shells):\n",
    "    \"\"\"Decodes a 1-D array into a [num_pao, num_prim] 2-D block.\"\"\"\n",
    "    xblock = []\n",
    "    i = 0\n",
    "    for l, m in enumerate(prim_basis_shells):\n",
    "        n = m * num_pao * (2 * l + 1)\n",
    "        xblock.append(xvec[i:i+n].reshape(num_pao, m * (2 * l + 1)))\n",
    "        i += n\n",
    "    return torch.cat(xblock, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prim = (\"s1\", \"s2\", \"p1x\", \"p1y\", \"p1z\", \"p2x\", \"p2y\", \"p2z\", \"d1xy\", \"d1yz\", \"d1zx\", \"d1xx\", \"d1zz\")\n",
    "# xblock = np.array([[\"%s,%i\"%(x,p) for x in prim ] for p in range(4)])\n",
    "# #print(xblock)\n",
    "# print(decode_xblock(encode_xblock(xblock, [2, 2, 1]), 4, [2, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data set... done.\n",
      "Epoch: 0  Missmatch: 249.332942  Penalty: 46.343033 Penalty2: 58.528950  Loss: 295.675975\n",
      "Epoch: 1  Missmatch: 229.367278  Penalty: 13.695913 Penalty2: 30.576676  Loss: 243.063191\n",
      "Epoch: 2  Missmatch: 224.588353  Penalty: 9.216397 Penalty2: 25.196316  Loss: 233.804749\n",
      "Epoch: 3  Missmatch: 189.114696  Penalty: 9.201641 Penalty2: 24.555421  Loss: 198.316337\n",
      "Epoch: 4  Missmatch: 172.864272  Penalty: 10.251939 Penalty2: 24.580058  Loss: 183.116212\n",
      "Epoch: 5  Missmatch: 167.749034  Penalty: 8.044005 Penalty2: 18.557395  Loss: 175.793039\n",
      "Epoch: 6  Missmatch: 157.598552  Penalty: 8.105738 Penalty2: 18.619628  Loss: 165.704290\n",
      "Epoch: 7  Missmatch: 111.583356  Penalty: 10.177019 Penalty2: 29.027988  Loss: 121.760375\n",
      "Epoch: 8  Missmatch: 59.655370  Penalty: 8.798397 Penalty2: 19.905064  Loss: 68.453768\n",
      "Epoch: 9  Missmatch: 40.497020  Penalty: 8.086329 Penalty2: 18.238406  Loss: 48.583348\n",
      "Epoch: 10  Missmatch: 34.794846  Penalty: 6.627623 Penalty2: 14.495787  Loss: 41.422469\n",
      "Epoch: 11  Missmatch: 32.201593  Penalty: 6.319978 Penalty2: 13.874955  Loss: 38.521571\n",
      "Epoch: 12  Missmatch: 26.619790  Penalty: 6.647764 Penalty2: 13.791292  Loss: 33.267555\n",
      "Epoch: 13  Missmatch: 25.868778  Penalty: 5.307278 Penalty2: 11.536179  Loss: 31.176056\n",
      "Epoch: 14  Missmatch: 25.122318  Penalty: 5.379837 Penalty2: 11.624083  Loss: 30.502155\n",
      "Epoch: 15  Missmatch: 21.613600  Penalty: 4.937311 Penalty2: 10.426201  Loss: 26.550911\n",
      "Epoch: 16  Missmatch: 19.899598  Penalty: 4.540686 Penalty2: 9.615853  Loss: 24.440284\n",
      "Epoch: 17  Missmatch: 19.726222  Penalty: 4.367644 Penalty2: 9.366084  Loss: 24.093867\n",
      "Epoch: 18  Missmatch: 21.040862  Penalty: 4.162148 Penalty2: 9.087432  Loss: 25.203010\n",
      "Epoch: 19  Missmatch: 21.902201  Penalty: 3.958590 Penalty2: 8.873129  Loss: 25.860791\n",
      "Epoch: 20  Missmatch: 18.354600  Penalty: 4.075822 Penalty2: 8.615115  Loss: 22.430421\n",
      "Epoch: 21  Missmatch: 18.155500  Penalty: 3.324975 Penalty2: 7.450527  Loss: 21.480475\n",
      "Epoch: 22  Missmatch: 18.589605  Penalty: 3.233284 Penalty2: 7.166721  Loss: 21.822889\n",
      "Epoch: 23  Missmatch: 18.285912  Penalty: 3.577127 Penalty2: 7.898927  Loss: 21.863038\n",
      "Epoch: 24  Missmatch: 18.437713  Penalty: 2.637652 Penalty2: 6.233774  Loss: 21.075364\n",
      "Epoch: 25  Missmatch: 19.132219  Penalty: 3.406802 Penalty2: 7.791751  Loss: 22.539021\n",
      "Epoch: 26  Missmatch: 18.170242  Penalty: 3.615677 Penalty2: 7.855109  Loss: 21.785919\n",
      "Epoch: 27  Missmatch: 14.941262  Penalty: 2.586927 Penalty2: 5.701462  Loss: 17.528189\n",
      "Epoch: 28  Missmatch: 16.083951  Penalty: 2.612487 Penalty2: 5.869578  Loss: 18.696438\n",
      "Epoch: 29  Missmatch: 14.937806  Penalty: 2.684579 Penalty2: 5.795604  Loss: 17.622385\n",
      "Epoch: 30  Missmatch: 14.543383  Penalty: 2.499091 Penalty2: 5.647234  Loss: 17.042474\n",
      "Epoch: 31  Missmatch: 14.400661  Penalty: 2.306661 Penalty2: 5.241117  Loss: 16.707322\n",
      "Epoch: 32  Missmatch: 13.862356  Penalty: 2.514016 Penalty2: 5.600825  Loss: 16.376372\n",
      "Epoch: 33  Missmatch: 17.656833  Penalty: 2.563300 Penalty2: 6.182272  Loss: 20.220133\n",
      "Epoch: 34  Missmatch: 15.200315  Penalty: 2.086826 Penalty2: 4.905843  Loss: 17.287141\n",
      "Epoch: 35  Missmatch: 14.121805  Penalty: 2.273602 Penalty2: 5.134872  Loss: 16.395407\n",
      "Epoch: 36  Missmatch: 13.022633  Penalty: 3.143128 Penalty2: 6.602805  Loss: 16.165761\n",
      "Epoch: 37  Missmatch: 13.835777  Penalty: 1.927212 Penalty2: 4.495945  Loss: 15.762989\n",
      "Epoch: 38  Missmatch: 13.910002  Penalty: 2.351756 Penalty2: 5.188079  Loss: 16.261758\n",
      "Epoch: 39  Missmatch: 14.919483  Penalty: 2.553210 Penalty2: 5.726786  Loss: 17.472693\n",
      "Epoch: 40  Missmatch: 13.842450  Penalty: 2.453996 Penalty2: 5.430192  Loss: 16.296447\n",
      "Epoch: 41  Missmatch: 12.347782  Penalty: 1.910336 Penalty2: 4.336980  Loss: 14.258118\n",
      "Epoch: 42  Missmatch: 13.277502  Penalty: 2.250679 Penalty2: 5.030836  Loss: 15.528180\n",
      "Epoch: 43  Missmatch: 14.592321  Penalty: 2.182101 Penalty2: 5.070282  Loss: 16.774422\n",
      "Epoch: 44  Missmatch: 12.329714  Penalty: 2.396703 Penalty2: 5.227787  Loss: 14.726416\n",
      "Epoch: 45  Missmatch: 11.447184  Penalty: 1.875905 Penalty2: 4.257385  Loss: 13.323088\n",
      "Epoch: 46  Missmatch: 12.038326  Penalty: 2.142527 Penalty2: 4.606075  Loss: 14.180853\n",
      "Epoch: 47  Missmatch: 13.132116  Penalty: 1.890436 Penalty2: 4.370153  Loss: 15.022552\n",
      "Epoch: 48  Missmatch: 12.491099  Penalty: 1.829298 Penalty2: 4.222726  Loss: 14.320397\n",
      "Epoch: 49  Missmatch: 13.866138  Penalty: 2.159964 Penalty2: 5.038253  Loss: 16.026103\n",
      "Epoch: 50  Missmatch: 14.801862  Penalty: 2.119476 Penalty2: 5.003945  Loss: 16.921338\n",
      "Epoch: 51  Missmatch: 12.914872  Penalty: 1.935089 Penalty2: 4.367539  Loss: 14.849961\n",
      "Epoch: 52  Missmatch: 14.856105  Penalty: 1.867426 Penalty2: 4.654194  Loss: 16.723531\n",
      "Epoch: 53  Missmatch: 12.845041  Penalty: 1.530975 Penalty2: 3.788880  Loss: 14.376016\n",
      "Epoch: 54  Missmatch: 11.806995  Penalty: 1.768734 Penalty2: 3.952373  Loss: 13.575729\n",
      "Epoch: 55  Missmatch: 11.450020  Penalty: 1.662398 Penalty2: 3.849206  Loss: 13.112418\n",
      "Epoch: 56  Missmatch: 12.023597  Penalty: 1.688549 Penalty2: 3.964270  Loss: 13.712146\n",
      "Epoch: 57  Missmatch: 11.837685  Penalty: 2.167639 Penalty2: 4.799713  Loss: 14.005324\n",
      "Epoch: 58  Missmatch: 12.030599  Penalty: 2.034113 Penalty2: 4.564520  Loss: 14.064712\n",
      "Epoch: 59  Missmatch: 13.046362  Penalty: 2.317666 Penalty2: 5.203095  Loss: 15.364027\n",
      "Epoch: 60  Missmatch: 11.426293  Penalty: 1.838601 Penalty2: 4.202740  Loss: 13.264894\n",
      "Epoch: 61  Missmatch: 11.606966  Penalty: 1.720079 Penalty2: 3.914592  Loss: 13.327045\n",
      "Epoch: 62  Missmatch: 12.283173  Penalty: 1.789756 Penalty2: 4.090959  Loss: 14.072929\n",
      "Epoch: 63  Missmatch: 11.848945  Penalty: 1.528243 Penalty2: 3.592692  Loss: 13.377188\n",
      "Epoch: 64  Missmatch: 11.103040  Penalty: 1.446548 Penalty2: 3.338245  Loss: 12.549588\n",
      "Epoch: 65  Missmatch: 10.344931  Penalty: 1.718035 Penalty2: 3.791764  Loss: 12.062966\n",
      "Epoch: 66  Missmatch: 10.457686  Penalty: 1.932680 Penalty2: 4.183485  Loss: 12.390366\n",
      "Epoch: 67  Missmatch: 10.696419  Penalty: 1.625799 Penalty2: 3.726990  Loss: 12.322218\n",
      "Epoch: 68  Missmatch: 10.606985  Penalty: 1.733891 Penalty2: 4.011124  Loss: 12.340876\n",
      "Epoch: 69  Missmatch: 10.962485  Penalty: 1.563319 Penalty2: 3.662082  Loss: 12.525804\n",
      "Epoch: 70  Missmatch: 10.187994  Penalty: 1.328987 Penalty2: 3.061905  Loss: 11.516981\n",
      "Epoch: 71  Missmatch: 10.089838  Penalty: 1.511593 Penalty2: 3.447137  Loss: 11.601431\n",
      "Epoch: 72  Missmatch: 9.656138  Penalty: 1.808893 Penalty2: 4.008738  Loss: 11.465031\n",
      "Epoch: 73  Missmatch: 10.469107  Penalty: 1.351707 Penalty2: 3.147579  Loss: 11.820814\n",
      "Epoch: 74  Missmatch: 11.431384  Penalty: 1.622891 Penalty2: 3.864363  Loss: 13.054275\n",
      "Epoch: 75  Missmatch: 10.457642  Penalty: 1.651471 Penalty2: 3.758756  Loss: 12.109113\n",
      "Epoch: 76  Missmatch: 11.264188  Penalty: 1.540564 Penalty2: 3.577797  Loss: 12.804753\n",
      "Epoch: 77  Missmatch: 11.905426  Penalty: 1.789325 Penalty2: 4.174617  Loss: 13.694751\n",
      "Epoch: 78  Missmatch: 10.867714  Penalty: 1.700784 Penalty2: 3.797498  Loss: 12.568498\n",
      "Epoch: 79  Missmatch: 10.407476  Penalty: 1.668527 Penalty2: 3.825954  Loss: 12.076003\n",
      "Epoch: 80  Missmatch: 10.068148  Penalty: 1.494550 Penalty2: 3.428182  Loss: 11.562698\n",
      "Epoch: 81  Missmatch: 9.761189  Penalty: 1.227203 Penalty2: 2.914055  Loss: 10.988392\n",
      "Epoch: 82  Missmatch: 9.931225  Penalty: 1.656053 Penalty2: 3.668126  Loss: 11.587278\n",
      "Epoch: 83  Missmatch: 11.530674  Penalty: 1.457773 Penalty2: 3.502667  Loss: 12.988447\n",
      "Epoch: 84  Missmatch: 10.217404  Penalty: 1.387642 Penalty2: 3.253610  Loss: 11.605046\n",
      "Epoch: 85  Missmatch: 11.885745  Penalty: 1.723554 Penalty2: 4.069182  Loss: 13.609298\n",
      "Epoch: 86  Missmatch: 9.852948  Penalty: 1.662269 Penalty2: 3.718231  Loss: 11.515218\n",
      "Epoch: 87  Missmatch: 9.669367  Penalty: 1.416741 Penalty2: 3.300869  Loss: 11.086109\n",
      "Epoch: 88  Missmatch: 9.863648  Penalty: 1.375761 Penalty2: 3.190056  Loss: 11.239408\n",
      "Epoch: 89  Missmatch: 10.523258  Penalty: 1.338634 Penalty2: 3.135547  Loss: 11.861891\n",
      "Epoch: 90  Missmatch: 9.784787  Penalty: 1.570129 Penalty2: 3.588033  Loss: 11.354916\n",
      "Epoch: 91  Missmatch: 9.917017  Penalty: 1.453752 Penalty2: 3.273164  Loss: 11.370770\n",
      "Epoch: 92  Missmatch: 9.520878  Penalty: 1.350918 Penalty2: 3.031513  Loss: 10.871795\n",
      "Epoch: 93  Missmatch: 9.387788  Penalty: 1.463719 Penalty2: 3.421926  Loss: 10.851507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94  Missmatch: 11.038090  Penalty: 1.248047 Penalty2: 3.118494  Loss: 12.286137\n",
      "Epoch: 95  Missmatch: 9.603326  Penalty: 1.284594 Penalty2: 3.053045  Loss: 10.887920\n",
      "Epoch: 96  Missmatch: 9.702466  Penalty: 1.517734 Penalty2: 3.462234  Loss: 11.220201\n",
      "Epoch: 97  Missmatch: 9.949712  Penalty: 1.429981 Penalty2: 3.387952  Loss: 11.379693\n",
      "Epoch: 98  Missmatch: 9.719977  Penalty: 1.175458 Penalty2: 2.933743  Loss: 10.895435\n",
      "Epoch: 99  Missmatch: 9.726586  Penalty: 1.336059 Penalty2: 3.034531  Loss: 11.062646\n"
     ]
    }
   ],
   "source": [
    "# assuming MOLOPT-DZVP as primary basis set\n",
    "prim_basis_shells = {\n",
    "    'H': [2, 1, 0], # two s-shells, one p-shell, no d-shells\n",
    "    'O': [2, 2, 1], # two s-shells, two p-shells, one d-shell\n",
    "}\n",
    "pao_basis_size = 4\n",
    "\n",
    "net = PAONet(num_kinds=2,\n",
    "             pao_basis_size=pao_basis_size,\n",
    "             prim_basis_shells=prim_basis_shells['O'],\n",
    "             num_hidden=1)\n",
    "net.train()\n",
    "dataset = PAODataset(\"O\")\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "import torch.nn.functional\n",
    "\n",
    "for epoch in range(100):\n",
    "    epoch_missmatch = 0\n",
    "    epoch_penalty = 0\n",
    "    epoch_penalty2 = 0\n",
    "    epoch_loss = 0\n",
    "    for batch in dataloader:\n",
    "        kind_onehot, coords, sample_indices = batch    \n",
    "        diff_M = se3cnn.point_utils.difference_matrix(coords)\n",
    "\n",
    "        # forward pass\n",
    "        output_net = net(kind_onehot, diff_M)\n",
    "\n",
    "        missmatch = torch.tensor(0.0)\n",
    "        penalty = torch.tensor(0.0)\n",
    "        penalty2 = torch.tensor(0.0)\n",
    "        for i, idx in enumerate(sample_indices):  # loop over batch\n",
    "            # We only care about the xblock of the central atom, which we rolled to the front.\n",
    "            xblock_enc_net = output_net[i,:,0]\n",
    "            \n",
    "            #decode xblock returned by network\n",
    "            xblock_net = decode_xblock(xblock_enc_net, pao_basis_size, prim_basis_shells['O'])\n",
    "            # We penalize non-unit vectors later, but we are not going to rely on it here.\n",
    "            xblock_net_unit = torch.nn.functional.normalize(xblock_net)\n",
    "            projector = torch.matmul(torch.t(xblock_net_unit), xblock_net_unit)\n",
    "            \n",
    "            residual = torch.t(xblock_sample) - torch.matmul(projector, torch.t(xblock_sample))\n",
    "            missmatch += torch.norm(residual)\n",
    "#             print(projector.shape)\n",
    "#             break\n",
    "\n",
    "#             # get complementary projector from training data\n",
    "#             sample_compl_projector = dataset.sample_compl_projector[idx]\n",
    "#             xblock_sample = dataset.sample_xblocks[idx]\n",
    "#             xblock_sample_unit = torch.nn.functional.normalize(xblock_sample)\n",
    "            \n",
    "#             # force spanning same space as training data\n",
    "#             residual = torch.matmul(sample_compl_projector, torch.t(xblock_net_unit))\n",
    "#             missmatch += torch.norm(residual)\n",
    "            \n",
    "            # penalize non-unit basis vector\n",
    "            penalty = torch.norm(1 - torch.norm(xblock_net, dim=1))\n",
    "            \n",
    "            overlap = torch.matmul(xblock_net, torch.t(xblock_net))\n",
    "            #print(torch.eye(4) - overlap)\n",
    "            #penalty2 = (1 - torch.det(overlap))**2\n",
    "            penalty2 = torch.norm(torch.eye(4) - overlap)\n",
    "               \n",
    "        loss = missmatch + penalty\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_missmatch += missmatch.item()\n",
    "        epoch_penalty += penalty.item()\n",
    "        epoch_penalty2 += penalty2.item()\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %i  Missmatch: %f  Penalty: %f Penalty2: %f  Loss: %f\"%(epoch, epoch_missmatch, epoch_penalty, epoch_penalty2, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
