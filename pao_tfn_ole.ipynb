{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pao_utils import parse_pao_file, append_samples\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import se3cnn\n",
    "import livelossplot as llp\n",
    "\n",
    "import sys, os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from se3cnn.utils import torch_default_dtype\n",
    "import se3cnn.point_utils as point_utils\n",
    "from se3cnn.non_linearities import NormSoftplus\n",
    "from se3cnn.convolution import SE3PointConvolution\n",
    "from se3cnn.blocks.point_norm_block import PointNormBlock \n",
    "from se3cnn.point_kernel import gaussian_radial_function\n",
    "from se3cnn.SO3 import torch_default_dtype\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from numpy.linalg import norm\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and parse all .pao files.\n",
    "# Each file corresponds to a molecular configuration, ie. a frame.\n",
    "# Since the system contains multiple atoms, each .pao file contains multiple samples.\n",
    "class PAODataset(object):\n",
    "    def __init__(self, kind_name):\n",
    "        self.kind_name = kind_name\n",
    "        self.sample_iatoms = []\n",
    "        self.sample_coords = []\n",
    "        self.sample_xblocks = []\n",
    "        self.sample_compl_projector = []\n",
    "        \n",
    "\n",
    "        #TODO split in training and test set\n",
    "        for fn in glob(\"2H2O_MD/frame_*/2H2O_pao44-1_0.pao\"):\n",
    "            kinds, atom2kind, coords, xblocks = parse_pao_file(fn)\n",
    "            for iatom, kind in enumerate(atom2kind):\n",
    "                if kind != self.kind_name:\n",
    "                    continue\n",
    "                rel_coords = coords - coords[iatom,:] # relative coordinates\n",
    "                self.sample_coords.append(rel_coords)\n",
    "                self.sample_xblocks.append(xblocks[iatom])\n",
    "                self.sample_iatoms.append(iatom)\n",
    "                \n",
    "                # orthonormalize xblock_sample's basis vectors (they deviate slightly)\n",
    "                #TODO: add a regularization term for this.\n",
    "                #\n",
    "                #https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process#Alternatives\n",
    "                V = torch.t(torch.from_numpy(xblocks[iatom]))  #TODO: use torch.tensor() instead?\n",
    "                VV  = torch.matmul(torch.t(V), V)\n",
    "                L = torch.cholesky(VV)\n",
    "                L_inv = torch.inverse(L)\n",
    "                U = torch.matmul(V, torch.t(L_inv))\n",
    "                projector = torch.matmul(U, torch.t(U))\n",
    "                identity = torch.eye(projector.shape[0])\n",
    "                compl_projector = identity - projector\n",
    "                self.sample_compl_projector.append(compl_projector)\n",
    "            \n",
    "\n",
    "        # assuming kinds and atom2kind are the same across whole training data\n",
    "        kinds_enum = list(kinds.keys())\n",
    "        self.kinds_onehot = np.zeros((len(kinds), len(atom2kind)))\n",
    "        for iatom, kind in enumerate(atom2kind):\n",
    "            idx = kinds_enum.index(kind)\n",
    "            self.kinds_onehot[idx, iatom] = 1.0\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # roll central atom to the front\n",
    "        iatom = self.sample_iatoms[idx]\n",
    "        rolled_kinds = np.roll(self.kinds_onehot, shift=-iatom, axis=1)\n",
    "        rolled_coords =  np.roll(self.sample_coords[idx], shift=-iatom, axis=0)  \n",
    "        return rolled_kinds, rolled_coords, idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_xblocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PAONet(torch.nn.Module):\n",
    "    def __init__(self, num_kinds, pao_basis_size, prim_basis_shells, num_hidden=1, num_radial=4, max_radius=2.5):\n",
    "        super().__init__()\n",
    "        self.num_kinds = num_kinds\n",
    "        self.prim_basis_shells = prim_basis_shells\n",
    "        self.pao_basis_size = pao_basis_size\n",
    "                \n",
    "        nonlinearity = lambda x: torch.log(0.5 * torch.exp(x) + 0.5)\n",
    "        sigma = max_radius / num_radial\n",
    "        radii = torch.linspace(0, max_radius, steps=num_radial, dtype=torch.float64)\n",
    "        radial_function = partial(gaussian_radial_function, sigma=2*sigma)\n",
    "        radii_args = {'radii': radii, 'radial_function': radial_function}\n",
    "        \n",
    "        # Convolutions with Norm nonlinearity layers\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        \n",
    "        # features\n",
    "        input_features = [num_kinds, 0, 0]  # L=0 for atom type as one-hot encoding\n",
    "        hidden_features = [8, 8, 8] # hidden layer with filters L=0,1,2\n",
    "        output_features = [i * pao_basis_size for i in prim_basis_shells]\n",
    "\n",
    "        # input layer\n",
    "        self.layers.append(PointNormBlock(input_features, hidden_features, activation=nonlinearity, **radii_args))\n",
    "       \n",
    "        # hidden layer\n",
    "        for _ in range(num_hidden):\n",
    "            self.layers.append(PointNormBlock(hidden_features, hidden_features, activation=nonlinearity, **radii_args))\n",
    "       \n",
    "        # output layer\n",
    "        Rs_repr = lambda features: [(m, l) for l, m in enumerate(features)]\n",
    "        self.layers.append(SE3PointConvolution(Rs_repr(hidden_features), Rs_repr(output_features), **radii_args))\n",
    "                        \n",
    "        \n",
    "    def forward(self, input, difference_mat, relative_mask=None):\n",
    "        output = input\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, difference_mat, relative_mask)\n",
    "        #TODO: things could be much simpler if the network directly returned decoded 2-D xblocks\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_xblock(xblock, prim_basis_shells):\n",
    "    \"\"\"Encodes a [num_pao, num_prim] 2D-block into a 1-D array\"\"\"\n",
    "    xvec = []\n",
    "    i = 0\n",
    "    for l, m in enumerate(prim_basis_shells):\n",
    "        n = m * (2 * l + 1)\n",
    "        xvec.append(xblock[:, i:i+n].flatten())\n",
    "        i += n\n",
    "    #return np.concatenate(xvec)\n",
    "    return torch.cat(xvec)\n",
    "\n",
    "def decode_xblock(xvec, num_pao, prim_basis_shells):\n",
    "    \"\"\"Decodes a 1-D array into a [num_pao, num_prim] 2-D block.\"\"\"\n",
    "    xblock = []\n",
    "    i = 0\n",
    "    for l, m in enumerate(prim_basis_shells):\n",
    "        n = m * num_pao * (2 * l + 1)\n",
    "        xblock.append(xvec[i:i+n].reshape(num_pao, m * (2 * l + 1)))\n",
    "        i += n\n",
    "    return torch.cat(xblock, dim=1)\n",
    "    #return np.concatenate(xblock, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prim = (\"s1\", \"s2\", \"p1x\", \"p1y\", \"p1z\", \"p2x\", \"p2y\", \"p2z\", \"d1xy\", \"d1yz\", \"d1zx\", \"d1xx\", \"d1zz\")\n",
    "# xblock = np.array([[\"%s,%i\"%(x,p) for x in prim ] for p in range(4)])\n",
    "# #print(xblock)\n",
    "# print(decode_xblock(encode_xblock(xblock, [2, 2, 1]), 4, [2, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Missmatch: 3.097995  Penalty: 0.323813  Loss: 3.421809\n",
      "Epoch: 1  Missmatch: 1.436323  Penalty: 0.323923  Loss: 1.760246\n",
      "Epoch: 2  Missmatch: 1.182246  Penalty: 0.323959  Loss: 1.506204\n",
      "Epoch: 3  Missmatch: 0.933909  Penalty: 0.323977  Loss: 1.257886\n",
      "Epoch: 4  Missmatch: 0.743917  Penalty: 0.323988  Loss: 1.067905\n",
      "Epoch: 5  Missmatch: 0.636164  Penalty: 0.323991  Loss: 0.960155\n",
      "Epoch: 6  Missmatch: 0.431013  Penalty: 0.323996  Loss: 0.755010\n",
      "Epoch: 7  Missmatch: 0.457076  Penalty: 0.323997  Loss: 0.781074\n",
      "Epoch: 8  Missmatch: 0.466386  Penalty: 0.323997  Loss: 0.790384\n",
      "Epoch: 9  Missmatch: 0.308929  Penalty: 0.323998  Loss: 0.632928\n",
      "Epoch: 10  Missmatch: 0.313987  Penalty: 0.323999  Loss: 0.637986\n",
      "Epoch: 11  Missmatch: 0.373679  Penalty: 0.323998  Loss: 0.697678\n",
      "Epoch: 12  Missmatch: 0.234489  Penalty: 0.323999  Loss: 0.558489\n",
      "Epoch: 13  Missmatch: 0.232583  Penalty: 0.323999  Loss: 0.556582\n",
      "Epoch: 14  Missmatch: 0.208619  Penalty: 0.323999  Loss: 0.532619\n",
      "Epoch: 15  Missmatch: 0.229747  Penalty: 0.323999  Loss: 0.553746\n",
      "Epoch: 16  Missmatch: 0.207339  Penalty: 0.323999  Loss: 0.531338\n",
      "Epoch: 17  Missmatch: 0.165385  Penalty: 0.324000  Loss: 0.489384\n",
      "Epoch: 18  Missmatch: 0.155428  Penalty: 0.324000  Loss: 0.479427\n",
      "Epoch: 19  Missmatch: 0.159309  Penalty: 0.324000  Loss: 0.483309\n",
      "Epoch: 20  Missmatch: 0.188952  Penalty: 0.324000  Loss: 0.512951\n",
      "Epoch: 21  Missmatch: 0.187298  Penalty: 0.324000  Loss: 0.511297\n",
      "Epoch: 22  Missmatch: 0.135551  Penalty: 0.324000  Loss: 0.459551\n",
      "Epoch: 23  Missmatch: 0.120575  Penalty: 0.324000  Loss: 0.444575\n",
      "Epoch: 24  Missmatch: 0.122357  Penalty: 0.324000  Loss: 0.446357\n",
      "Epoch: 25  Missmatch: 0.124017  Penalty: 0.324000  Loss: 0.448017\n",
      "Epoch: 26  Missmatch: 0.113955  Penalty: 0.324000  Loss: 0.437955\n",
      "Epoch: 27  Missmatch: 0.108981  Penalty: 0.324000  Loss: 0.432980\n",
      "Epoch: 28  Missmatch: 0.112516  Penalty: 0.324000  Loss: 0.436515\n",
      "Epoch: 29  Missmatch: 0.095895  Penalty: 0.324000  Loss: 0.419895\n",
      "Epoch: 30  Missmatch: 0.095621  Penalty: 0.324000  Loss: 0.419621\n",
      "Epoch: 31  Missmatch: 0.103572  Penalty: 0.324000  Loss: 0.427571\n",
      "Epoch: 32  Missmatch: 0.110183  Penalty: 0.324000  Loss: 0.434182\n",
      "Epoch: 33  Missmatch: 0.071216  Penalty: 0.324000  Loss: 0.395216\n",
      "Epoch: 34  Missmatch: 0.078243  Penalty: 0.324000  Loss: 0.402243\n",
      "Epoch: 35  Missmatch: 0.080530  Penalty: 0.324000  Loss: 0.404529\n",
      "Epoch: 36  Missmatch: 0.076668  Penalty: 0.324000  Loss: 0.400668\n",
      "Epoch: 37  Missmatch: 0.088406  Penalty: 0.324000  Loss: 0.412406\n",
      "Epoch: 38  Missmatch: 0.066730  Penalty: 0.324000  Loss: 0.390730\n",
      "Epoch: 39  Missmatch: 0.086895  Penalty: 0.324000  Loss: 0.410895\n",
      "Epoch: 40  Missmatch: 0.072452  Penalty: 0.324000  Loss: 0.396451\n",
      "Epoch: 41  Missmatch: 0.060835  Penalty: 0.324000  Loss: 0.384835\n",
      "Epoch: 42  Missmatch: 0.063150  Penalty: 0.324000  Loss: 0.387150\n",
      "Epoch: 43  Missmatch: 0.060601  Penalty: 0.324000  Loss: 0.384601\n",
      "Epoch: 44  Missmatch: 0.061073  Penalty: 0.324000  Loss: 0.385073\n"
     ]
    }
   ],
   "source": [
    "# assuming MOLOPT-DZVP as primary basis set\n",
    "prim_basis_shells = {\n",
    "    'H': [2, 1, 0], # two s-shells, one p-shell, no d-shells\n",
    "    'O': [2, 2, 1], # two s-shells, two p-shells, one d-shell\n",
    "}\n",
    "\n",
    "net = PAONet(num_kinds=2, pao_basis_size=4, prim_basis_shells=prim_basis_shells['O'], num_hidden=2)\n",
    "net.train()\n",
    "dataset = PAODataset(\"O\")\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "import torch.nn.functional\n",
    "\n",
    "for epoch in range(100):\n",
    "    epoch_missmatch = 0\n",
    "    epoch_penalty = 0\n",
    "    epoch_loss = 0\n",
    "    for batch in dataloader:\n",
    "        kind_onehot, coords, sample_indices = batch    \n",
    "        diff_M = se3cnn.point_utils.difference_matrix(coords)\n",
    "\n",
    "        # forward pass\n",
    "        output_net = net(kind_onehot, diff_M)\n",
    "\n",
    "        # Use Hungarian algorithm to align training data sample to network's output.\n",
    "\n",
    "        missmatch = torch.tensor(0.0)\n",
    "        penalty = torch.tensor(0.0)\n",
    "        for i, idx in enumerate(sample_indices):  # loop over batch\n",
    "            # We only care about the xblock of the central atom, which we rolled to the front.\n",
    "            xblock_enc_net = output_net[i,:,0]\n",
    "            \n",
    "            # decode xblock returned by network\n",
    "            #xblock_net = decode_xblock(xblock_enc_net.detach().numpy(), 4, prim_basis_shells['O'])\n",
    "            xblock_net = decode_xblock(xblock_enc_net, 4, prim_basis_shells['O'])\n",
    "            \n",
    "            # get complementary projector from training data\n",
    "            sample_compl_projector = dataset.sample_compl_projector[idx]\n",
    "            \n",
    "            # force spanning same space as training data\n",
    "            residual = torch.matmul(compl_projector, torch.t(xblock_net))\n",
    "            missmatch += torch.norm(residual)\n",
    "            \n",
    "            # force returning orthonormal vectors\n",
    "            identity_pao = torch.eye(xblock_net.shape[0])\n",
    "            non_orthonormality = identity_pao - torch.matmul(xblock_net, torch.t(xblock_net))\n",
    "            penalty += 0.001 * torch.norm(non_orthonormality)\n",
    "        \n",
    "        loss = missmatch + penalty\n",
    "        \n",
    "        epoch_missmatch += missmatch.item()\n",
    "        epoch_penalty += penalty.item()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %i  Missmatch: %f  Penalty: %f  Loss: %f\"%(epoch, epoch_missmatch, epoch_penalty, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
