{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pao_utils import parse_pao_file, append_samples\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import se3cnn\n",
    "import livelossplot as llp\n",
    "\n",
    "import sys, os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from se3cnn.utils import torch_default_dtype\n",
    "import se3cnn.point_utils as point_utils\n",
    "from se3cnn.non_linearities import NormSoftplus\n",
    "from se3cnn.convolution import SE3PointConvolution\n",
    "from se3cnn.blocks.point_norm_block import PointNormBlock \n",
    "from se3cnn.point_kernel import gaussian_radial_function\n",
    "from se3cnn.SO3 import torch_default_dtype\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from numpy.linalg import norm\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and parse all .pao files.\n",
    "# Each file corresponds to a molecular configuration, ie. a frame.\n",
    "# Since the system contains multiple atoms, each .pao file contains multiple samples.\n",
    "class PAODataset(object):\n",
    "    def __init__(self, kind_name):\n",
    "        self.kind_name = kind_name\n",
    "        self.sample_coords = []\n",
    "        self.sample_xblocks = []\n",
    "        self.sample_iatoms = []\n",
    "\n",
    "        #TODO split in training and test set\n",
    "        for fn in glob(\"2H2O_MD/frame_*/2H2O_pao44-1_0.pao\"):\n",
    "            kinds, atom2kind, coords, xblocks = parse_pao_file(fn)\n",
    "            for iatom, kind in enumerate(atom2kind):\n",
    "                if kind != self.kind_name:\n",
    "                    continue\n",
    "                rel_coords = coords - coords[iatom,:] # relative coordinates\n",
    "                self.sample_coords.append(rel_coords)\n",
    "                self.sample_xblocks.append(xblocks[iatom])\n",
    "                self.sample_iatoms.append(iatom)\n",
    "\n",
    "        # assuming kinds and atom2kind are the same across whole training data\n",
    "        kinds_enum = list(kinds.keys())\n",
    "        self.kinds_onehot = np.zeros((len(kinds), len(atom2kind)))\n",
    "        for iatom, kind in enumerate(atom2kind):\n",
    "            idx = kinds_enum.index(kind)\n",
    "            self.kinds_onehot[idx, iatom] = 1.0\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # roll central atom to the front\n",
    "        iatom = self.sample_iatoms[idx]\n",
    "        rolled_kinds = np.roll(self.kinds_onehot, shift=-iatom, axis=1)\n",
    "        rolled_coords =  np.roll(self.sample_coords[idx], shift=-iatom, axis=0)  \n",
    "        return rolled_kinds, rolled_coords, idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_xblocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PAONet(torch.nn.Module):\n",
    "    def __init__(self, num_kinds, pao_basis_size, prim_basis_shells, num_radial=4, max_radius=2.5):\n",
    "        super().__init__()\n",
    "        self.num_kinds = num_kinds\n",
    "        self.prim_basis_shells = prim_basis_shells\n",
    "        self.pao_basis_size = pao_basis_size\n",
    "        \n",
    "        features = []\n",
    "        features.append([num_kinds, 0, 0])  # L=0 for atom type as one-hot encoding\n",
    "        features.append([8, 8, 8]) # hidden layer with filters L=0,1,2\n",
    "        features.append([8, 8, 8]) # hidden layer with filters L=0,1,2\n",
    "        features.append([ i * pao_basis_size for i in prim_basis_shells])\n",
    "\n",
    "        nonlinearity = lambda x: torch.log(0.5 * torch.exp(x) + 0.5)\n",
    "        sigma = max_radius / num_radial\n",
    "        radii = torch.linspace(0, max_radius, steps=num_radial, dtype=torch.float64)\n",
    "        radial_function = partial(gaussian_radial_function, sigma=2*sigma)\n",
    "        radii_args = {'radii': radii, 'radial_function': radial_function}\n",
    "\n",
    "        # Convolutions with Norm nonlinearity layers\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        \n",
    "        # input layer\n",
    "        self.layers.append(PointNormBlock(features[0], features[1], activation=nonlinearity, **radii_args))\n",
    "        \n",
    "        # hidden layer\n",
    "        self.layers.append(PointNormBlock(features[1], features[2], activation=nonlinearity, **radii_args))\n",
    "        \n",
    "        # output layer\n",
    "        Rs_repr = lambda features: [(m, l) for l, m in enumerate(features)]\n",
    "        self.layers.append(SE3PointConvolution(Rs_repr(features[2]), Rs_repr(features[3]), **radii_args))\n",
    "                        \n",
    "        \n",
    "    def forward(self, input, difference_mat, relative_mask=None):\n",
    "        output = input\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, difference_mat, relative_mask)\n",
    "        return output\n",
    "\n",
    "        #TODO: this could make things a lot simpler:\n",
    "        ## decode network's 1-D output into 2-D xblock with shape [num_pao, num_prim].\n",
    "        #xblock = output.reshape(-1, self.pao_basis_size).transpose()\n",
    "        #return xblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror(xblock):\n",
    "    \"\"\" duplicate pao vectors with flipped sign \"\"\"\n",
    "    m, n = xblock.shape # size of pao and prim basis\n",
    "    result = np.zeros((2*m, n))\n",
    "    result[:m,:] = xblock\n",
    "    result[m:,:] = -xblock\n",
    "    return result\n",
    "\n",
    "def align(xblock, ref_xblock):\n",
    "    \"\"\" align xblock onto ref_xblock in-place \"\"\"\n",
    "    m, n = xblock.shape # size of pao and prim basis\n",
    "    \n",
    "    # We can treat sign-flips as permutations by including each basis vector with both signs.\n",
    "    a = mirror(xblock)\n",
    "    b = mirror(ref_xblock)\n",
    "    \n",
    "    # build distance matrix\n",
    "    dist = np.zeros((2*m,2*m))\n",
    "    for i in range(2*m):\n",
    "        for j in range(2*m):\n",
    "            dist[i,j] = norm(a[i,:] - b[j,:])\n",
    "            \n",
    "    # run Hungarian algorithm\n",
    "    row_ind, col_ind = linear_sum_assignment(dist)\n",
    "\n",
    "    # permute pao basis vectors in-place\n",
    "    permutations = 0\n",
    "    for i, j in enumerate(col_ind[:m]):\n",
    "        permutations += int(i != j)\n",
    "        xblock[i,:] = a[j,:]\n",
    "\n",
    "    return permutations # number of permutations, should approach zero as training progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_xblock(xblock, prim_basis_shells):\n",
    "    \"\"\"Encodes a [num_pao, num_prim] 2D-block into a 1-D array\"\"\"\n",
    "    xvec = []\n",
    "    i = 0\n",
    "    for l, m in enumerate(prim_basis_shells):\n",
    "        n = m * (2 * l + 1)\n",
    "        xvec.append(xblock[:, i:i+n].flatten())\n",
    "        i += n\n",
    "    return np.concatenate(xvec)\n",
    "\n",
    "def decode_xblock(xvec, num_pao, prim_basis_shells):\n",
    "    \"\"\"Decodes a 1-D array into a [num_pao, num_prim] 2-D block.\"\"\"\n",
    "    xblock = []\n",
    "    i = 0\n",
    "    for l, m in enumerate(prim_basis_shells):\n",
    "        n = m * num_pao * (2 * l + 1)\n",
    "        xblock.append(xvec[i:i+n].reshape(num_pao, m * (2 * l + 1)))\n",
    "        i += n\n",
    "    return np.concatenate(xblock, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim = (\"s1\", \"s2\", \"p1x\", \"p1y\", \"p1z\", \"p2x\", \"p2y\", \"p2z\", \"d1xy\", \"d1yz\", \"d1zx\", \"d1xx\", \"d1zz\")\n",
    "xblock = np.array([[\"%s,%i\"%(x,p) for x in prim ] for p in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 2.087192 Permutations: 437\n",
      "Epoch: 1 Loss: 1.185242 Permutations: 136\n",
      "Epoch: 2 Loss: 0.807268 Permutations: 92\n",
      "Epoch: 3 Loss: 0.509907 Permutations: 53\n",
      "Epoch: 4 Loss: 0.380037 Permutations: 24\n",
      "Epoch: 5 Loss: 0.291385 Permutations: 12\n",
      "Epoch: 6 Loss: 0.247453 Permutations: 14\n",
      "Epoch: 7 Loss: 0.229705 Permutations: 10\n",
      "Epoch: 8 Loss: 0.225291 Permutations: 12\n",
      "Epoch: 9 Loss: 0.208763 Permutations: 14\n",
      "Epoch: 10 Loss: 0.194447 Permutations: 12\n",
      "Epoch: 11 Loss: 0.181160 Permutations: 12\n",
      "Epoch: 12 Loss: 0.171960 Permutations: 12\n",
      "Epoch: 13 Loss: 0.162915 Permutations: 8\n",
      "Epoch: 14 Loss: 0.158637 Permutations: 8\n"
     ]
    }
   ],
   "source": [
    "# assuming MOLOPT-DZVP as primary basis set\n",
    "prim_basis_shells = {\n",
    "    'H': [2, 1, 0], # two s-shells, one p-shell, no d-shells\n",
    "    'O': [2, 2, 1], # two s-shells, two p-shells, one d-shell\n",
    "}\n",
    "\n",
    "net = PAONet(num_kinds=2, pao_basis_size=4, prim_basis_shells=prim_basis_shells['O'])\n",
    "net.train()\n",
    "dataset = PAODataset(\"O\")\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "for epoch in range(100):\n",
    "    epoch_permutations = 0\n",
    "    epoch_loss = 0\n",
    "    for batch in dataloader:\n",
    "        kind_onehot, coords, sample_indices = batch    \n",
    "        diff_M = se3cnn.point_utils.difference_matrix(coords)\n",
    "\n",
    "        # forward pass\n",
    "        output_net = net(kind_onehot, diff_M)\n",
    "\n",
    "        # Use Hungarian algorithm to align training data sample to network's output.\n",
    "\n",
    "        output_sample = []\n",
    "        for i, idx in enumerate(sample_indices):  # loop over batch\n",
    "            # We only care about the xblock of the central atom, which we rolled to the front.\n",
    "            xblock_enc_net = output_net[i,:,0]\n",
    "            \n",
    "            # decode xblock returned by network\n",
    "            xblock_net = decode_xblock(xblock_enc_net.detach().numpy(), 4, prim_basis_shells['O'])\n",
    "            \n",
    "            # get xblock from training data\n",
    "            xblock_sample = dataset.sample_xblocks[idx]\n",
    "            \n",
    "            # aligh sample xblock onto xblock outputed by the network\n",
    "            epoch_permutations += align(xblock_sample, xblock_net)\n",
    "            \n",
    "            # encode aligned sample xblock\n",
    "            output_sample.append(encode_xblock(xblock_sample, prim_basis_shells['O']))\n",
    "\n",
    "\n",
    "        # Compute loss\n",
    "        output_sample = torch.tensor(output_sample)\n",
    "        loss = loss_fn(output_net[:,:,0], output_sample)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %i Loss: %f Permutations: %i\"%(epoch, epoch_loss, epoch_permutations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
