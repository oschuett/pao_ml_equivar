{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd9f918",
   "metadata": {},
   "source": [
    "# Demo for PAO-ML via e3nn\n",
    "\n",
    "See also https://docs.e3nn.org/en/latest/guide/convolution.html\n",
    "\n",
    "## Requirements:\n",
    "```\n",
    "pip install --upgrade e3nn torch_cluster torch_scatter matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pao_file_utils import parse_pao_file, write_pao_file, read_cp2k_energy\n",
    "import torch\n",
    "from e3nn import o3, nn\n",
    "from e3nn.math import soft_one_hot_linspace\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "t = torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b0f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenient wrapper that returns torch Tensors\n",
    "def parse_pao_file_torch(path: Path):\n",
    "    kinds, atom2kind, coords, xblocks = parse_pao_file(path)\n",
    "    return kinds, atom2kind, t(coords, dtype=torch.float32), [t(x, dtype=torch.float32) for x in xblocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1cb396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load single training sample.\n",
    "kinds, atom2kind, coords, xblocks = parse_pao_file_torch(Path(\"./2H2O_rotations/phi_00/2H2O_pao44-1_0.pao\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4168b857",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_KIND = \"H\" # The atom kinds for which we're training.\n",
    "TRAINING_ATOMS = [i for i, kind in enumerate(atom2kind) if kind == TRAINING_KIND]\n",
    "assert all(atom2kind[i]  == TRAINING_KIND for i in TRAINING_ATOMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a2074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irreps Input\n",
    "irreps_input = o3.Irreps(\"2x0e\") # features: is_hydrogen, is_oxygen\n",
    "#irreps_input = o3.Irreps(\"6x0e\") # feature: atom index as one hot !!! THIS IS A BIG HACK !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbaebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irreps Output\n",
    "pao_basis_size = 4\n",
    "prim_basis_specs = {\n",
    "    \"O\": \"2x0e + 2x1o + 1x2e\", # DZVP-MOLOPT-GTH for Oxygen: two s-shells, two p-shells, one d-shell\n",
    "    \"H\": \"2x0e + 1x1o\" # DZVP-MOLOPT-GTH for Hydrogen: two s-shells, one p-shell\n",
    "}\n",
    "prim_basis_spec = prim_basis_specs[TRAINING_KIND]\n",
    "prim_basis_size = o3.Irreps(prim_basis_spec).dim\n",
    "irreps_output = o3.Irreps(\" + \".join(pao_basis_size*[prim_basis_spec]))\n",
    "for iatom in TRAINING_ATOMS:\n",
    "    assert irreps_output.dim == xblocks[iatom].flatten().size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irreps Spherical Harmonics\n",
    "irreps_sh = o3.Irreps.spherical_harmonics(lmax=irreps_output.lmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85891323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Product\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    tp = o3.FullyConnectedTensorProduct(irreps_input, irreps_sh, irreps_output, shared_weights=False)\n",
    "print(tp.weight_numel)\n",
    "tp.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27648358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "num_distances = 10\n",
    "num_layers = 8\n",
    "# Note ReLu does not work well because many of the distance buckets from soft_one_hot_linspace are zero.\n",
    "fc = nn.FullyConnectedNet([num_distances, num_layers, tp.weight_numel], torch.sigmoid) # relu does not \n",
    "print(\"Number of parameters: \", sum(p.numel() for p in fc.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f60e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input of each node is whether it's an oxygen or not.\n",
    "num_neighbors = 6 # TODO: Remove the central atom, it doesn't carry any information.\n",
    "assert coords.shape[0] == num_neighbors\n",
    "f_in = t([(k==\"H\", k==\"O\") for k in atom2kind], dtype=torch.float32).mul(num_neighbors**0.5)\n",
    "\n",
    "#f_in = torch.eye(num_neighbors) #  atom index as one hot #TODO: !!! THIS IS A BIG HACK  !!!\n",
    "assert f_in.shape[0] == num_neighbors and f_in.shape[1] == irreps_input.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8264393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP2K uses the yzx convention, while e3nn uses xyz.\n",
    "# https://docs.e3nn.org/en/stable/guide/change_of_basis.html\n",
    "change_of_coord = torch.tensor([[0., 0., 1.],[1., 0., 0.],[0., 1., 0.]]) # yzx -> xyz\n",
    "D = irreps_output.D_from_matrix(change_of_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c60e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model and loss function.\n",
    "max_radius = 2\n",
    "\n",
    "def loss_function(pred, label):\n",
    "    p1 = pred.T @ pred\n",
    "    p2 = label.T @ label # is a projector because labels are orthonormal\n",
    "    return (p1 - p2).pow(2).sum()\n",
    "\n",
    "def model(edge_vec):\n",
    "    sh = o3.spherical_harmonics(irreps_sh, edge_vec, normalize=True, normalization='component')\n",
    "    emb = soft_one_hot_linspace(edge_vec.norm(dim=1), 0.0, max_radius, num_distances,\n",
    "                                basis='smooth_finite', cutoff=True).mul(num_distances**0.5)\n",
    "    flat_xyz = tp(f_in, sh, fc(emb)).sum(dim=0).div(num_neighbors**0.5)\n",
    "    flat_yzx = flat_xyz @ D\n",
    "    return flat_yzx.reshape(pao_basis_size, prim_basis_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0542eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels.\n",
    "def labelfy(xblock):\n",
    "    # The loss_functions requires orthonormal labels.\n",
    "    U, S, Vh = torch.linalg.svd(xblock, full_matrices=False)\n",
    "    return Vh\n",
    "\n",
    "labels = [labelfy(xblocks[i]) for i in TRAINING_ATOMS]\n",
    "edge_vecs = [coords - coords[i] for i in TRAINING_ATOMS]\n",
    "#edge_vecs[0][2,2] += 0.5 #HACK!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(fc.parameters())\n",
    "num_steps= 15001\n",
    "for step in range(num_steps):\n",
    "    optim.zero_grad()\n",
    "    loss_values = \"\"\n",
    "    for edge_vec, label in zip(edge_vecs, labels):\n",
    "        pred = model(edge_vec)\n",
    "        loss = loss_function(pred, label)\n",
    "        #loss = (pred - label).pow(2).sum()\n",
    "        loss.backward()\n",
    "        loss_values += (f\"  {loss:.8e}\")\n",
    "    if step % 1000 == 0:\n",
    "        print(f\"training {step:5d} | loss {loss_values}\")\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e34a2f9",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ca6f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test against rotated training samples using loss functions\n",
    "for path in sorted(Path().glob(\"2H2O_rotations/rand_*/2H2O_pao44-1_0.pao\"))[:10]:\n",
    "    _, _, test_coords, test_xblocks = parse_pao_file_torch(path)\n",
    "    for i in TRAINING_ATOMS:\n",
    "        edge_vec = test_coords - test_coords[i]\n",
    "        test_loss = loss_function(model(edge_vec), labelfy(test_xblocks[i]))\n",
    "        print(f\"{path}: atom: {i} lost: {test_loss:e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3666deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test against randomly rotated training samples using CP2K.\n",
    "for path in sorted(Path().glob(\"2H2O_rotations/rand_*/2H2O_pao44-1_0.pao\")):\n",
    "    _, _, sample_coords, sample_xblocks = parse_pao_file_torch(path)\n",
    "    pred_xblocks = sample_xblocks.copy()\n",
    "    for i in TRAINING_ATOMS:\n",
    "        edge_vec = sample_coords - sample_coords[i]\n",
    "        pred_xblocks[i] = model(edge_vec)\n",
    "    write_pao_file(path.parent / \"2H2O_pao44_eval.pao\", kinds, atom2kind, sample_coords, pred_xblocks)\n",
    "    ! cd {path.parent}; OMP_NUM_THREADS=8 ~/git/cp2k/exe/local/cp2k.sdbg 2H2O_pao44_eval.inp > 2H2O_pao44_eval.out\n",
    "    test_energy = read_cp2k_energy(path.parent / \"2H2O_pao44_eval.out\")\n",
    "    ref_energy = read_cp2k_energy(path.parent / \"2H2O_pao44.out\")\n",
    "    rel_diff_energy = (test_energy - ref_energy) / ref_energy\n",
    "    print(f\"{path}: Relative Energy Diff: {rel_diff_energy:e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
