{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import itertools\n",
    "from pao_file_utils import parse_pao_file\n",
    "from sympy.physics.quantum.cg import CG\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/cp2k/cp2k/blob/master/src/common/spherical_harmonics.F\n",
    "def Y_l(r, l):\n",
    "    \"\"\"Real Spherical Harmonics\"\"\"\n",
    "    assert r.shape[-1] == 3\n",
    "\n",
    "    if l < 0:\n",
    "        raise Exceptoin(\"Negative l value\")\n",
    "    elif l == 0:\n",
    "        return np.sqrt(1.0 / (4.0 * np.pi))\n",
    "    elif l == 1:\n",
    "        pf = np.sqrt(3.0 / (4.0 * np.pi))\n",
    "        return pf * r\n",
    "    elif l == 2:\n",
    "        x = r[..., 0]\n",
    "        y = r[..., 1]\n",
    "        z = r[..., 2]\n",
    "        result = np.zeros(5)\n",
    "        # m = 2\n",
    "        pf = np.sqrt(15.0 / (16.0 * np.pi))\n",
    "        result[0] = pf * x**2 - y**2\n",
    "        # m = 1\n",
    "        pf = np.sqrt(15.0 / (4.0 * np.pi))\n",
    "        result[1] = pf * z * x\n",
    "        # m = 0\n",
    "        pf = np.sqrt(5.0 / (16.0 * np.pi))\n",
    "        result[2] = pf * (3.0 * z**2 - 1.0)\n",
    "        # m = -1\n",
    "        pf = np.sqrt(15.0 / (4.0 * np.pi))\n",
    "        result[3] = pf * z * y\n",
    "        # m = -2\n",
    "        pf = np.sqrt(15.0 / (16.0 * np.pi))\n",
    "        result[4] = pf * 2.0 * x * y\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolute(coords, atom2kind, central_atom, max_l):\n",
    "    natoms = coords.shape[0]\n",
    "    assert coords.shape[1] == 3\n",
    "    kind_names = list(sorted(set(atom2kind)))\n",
    "    integrals = []\n",
    "    for l in range(max_l + 1):\n",
    "        for sigma in [0.5, 1.0, 2.0, 3.0, 4.0]:\n",
    "            for ikind in kind_names:\n",
    "                integrals.append(np.zeros(2*l + 1))\n",
    "                for iatom in range(natoms):\n",
    "                    if atom2kind[iatom] == ikind and iatom != central_atom:\n",
    "                        r = coords[central_atom] - coords[iatom]\n",
    "                        angular_part = Y_l(r, l)\n",
    "                        radial_part = np.exp(- np.dot(r,r) / sigma**2)\n",
    "                        integrals[-1] += radial_part * angular_part\n",
    "    return integrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_cache = dict()\n",
    "\n",
    "#TODO maybe rename lo -> lk ?\n",
    "def get_clebsch_gordan_coefficients(li, lj, lo):\n",
    "    global cg_cache\n",
    "    key = (li, lj, lo)\n",
    "    if key not in cg_cache:\n",
    "        assert abs(li-lj) <= lo <= abs(li+lj)\n",
    "        coeffs = np.zeros(shape=(2*li+1, 2*lj+1, 2*lo+1))\n",
    "        for mi in range(-li, li+1):\n",
    "            for mj in range(-lj, lj+1):\n",
    "                for mo in range(-lo, lo+1):\n",
    "                    # https://docs.sympy.org/latest/modules/physics/quantum/cg.html\n",
    "                    cg = CG(li, mi, lj, mj, lo, mo).doit()\n",
    "                    coeffs[mi+li, mj+lj, mo+lo] = cg\n",
    "        cg_cache[key] = coeffs\n",
    "    return cg_cache[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(channels, max_l):\n",
    "    \"\"\" returns all possbile combinations of input channels up to given max_l \"\"\"\n",
    "    output_channels = list()\n",
    "    for channel_i, channel_j in itertools.combinations_with_replacement(channels, 2):\n",
    "        assert len(channel_i.shape) == len(channel_j.shape) == 1\n",
    "        li = (channel_i.size - 1) // 2\n",
    "        lj = (channel_j.size - 1) // 2\n",
    "        # There li + lj possible ways to combine the two channels.\n",
    "        # We do all of them up to a max_l.\n",
    "        lo_min = abs(li-lj)\n",
    "        lo_max = min(li+lj, max_l)\n",
    "        for lo in range(lo_min, lo_max + 1): # l of output\n",
    "            channel_o = np.zeros(2*lo+1)\n",
    "            cg = get_clebsch_gordan_coefficients(li, lj, lo)\n",
    "            channel_o = np.einsum(\"i,j,ijo->o\", channel_i, channel_j, cg)\n",
    "            output_channels.append(channel_o)\n",
    "    return output_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data and hard code metadata.\n",
    "pao_files = sorted(glob(\"2H2O_MD/frame_*/2H2O_pao44-1_0.pao\"))\n",
    "\n",
    "prim_basis_shells = {\n",
    "    'H': [2, 1, 0], # two s-shells, one p-shell, no d-shells\n",
    "    'O': [2, 2, 1], # two s-shells, two p-shells, one d-shell\n",
    "}\n",
    "\n",
    "pao_basis_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset for:  H\n",
      "samples:  324\n",
      "s channels:  110\n",
      "p channels:  155\n",
      "d channels:  0\n",
      "\n",
      "Dataset for:  O\n",
      "samples:  162\n",
      "s channels:  165\n",
      "p channels:  310\n",
      "d channels:  310\n"
     ]
    }
   ],
   "source": [
    "class Sample:\n",
    "    def __init__(self, channels, xblock):\n",
    "        self.channels = channels\n",
    "        self.xblock = xblock\n",
    "        #TODO generalize\n",
    "        self.s_channel_list = [c for c in channels if c.size == 1]\n",
    "        self.p_channel_list = [c for c in channels if c.size == 3]\n",
    "        self.d_channel_list = [c for c in channels if c.size == 5]\n",
    "\n",
    "        self.s_channels = np.concatenate(self.s_channel_list)\n",
    "        self.p_channels = np.stack(self.p_channel_list).T\n",
    "        if (self.d_channel_list):\n",
    "            self.d_channels = np.stack(self.d_channel_list).T\n",
    "        else:\n",
    "            self.d_channels = np.zeros(shape=[])\n",
    "\n",
    "def build_dataset(kind_name, max_l):\n",
    "    samples = []\n",
    "    for fn in pao_files:\n",
    "        kinds, atom2kind, coords, xblocks = parse_pao_file(fn)\n",
    "        #kind_onehot = encode_kind(atom2kind)\n",
    "        natoms = coords.shape[0]\n",
    "        for iatom in range(natoms):\n",
    "            if atom2kind[iatom] == kind_name:\n",
    "                initial_channels = convolute(coords, atom2kind, iatom, max_l)\n",
    "                comb_channels = combinations(initial_channels, max_l)\n",
    "                sample = Sample(comb_channels, xblocks[iatom])\n",
    "                samples.append(sample)\n",
    "\n",
    "    print(\"\\nDataset for: \", kind_name)\n",
    "    print(\"samples: \", len(samples))\n",
    "    print(\"s channels: \", len(samples[0].s_channel_list))\n",
    "    print(\"p channels: \", len(samples[0].p_channel_list))\n",
    "    print(\"d channels: \", len(samples[0].d_channel_list))\n",
    "    return samples\n",
    "    \n",
    "H_dataset = build_dataset(\"H\", max_l=1)\n",
    "O_dataset = build_dataset(\"O\", max_l=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(H_dataset[0].s_channels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_45\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "s_input (InputLayer)            [(None, 110)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer (Dense)            (None, 8)            888         s_input[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "coeffs_010 (Dense)              (None, 155)          1395        hidden_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "p_input (InputLayer)            [(None, 3, 155)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coeffs_110 (Dense)              (None, 155)          1395        hidden_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "coeffs_210 (Dense)              (None, 155)          1395        hidden_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "coeffs_310 (Dense)              (None, 155)          1395        hidden_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "coeffs_000 (Dense)              (None, 1)            9           hidden_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "coeffs_001 (Dense)              (None, 1)            9           hidden_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "contr_010 (Lambda)              (None, 3)            0           coeffs_010[0][0]                 \n",
      "                                                                 p_input[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "coeffs_100 (Dense)              (None, 1)            9           hidden_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "coeffs_101 (Dense)              (None, 1)            9           hidden_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "contr_110 (Lambda)              (None, 3)            0           coeffs_110[0][0]                 \n",
      "                                                                 p_input[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "coeffs_200 (Dense)              (None, 1)            9           hidden_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "coeffs_201 (Dense)              (None, 1)            9           hidden_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "contr_210 (Lambda)              (None, 3)            0           coeffs_210[0][0]                 \n",
      "                                                                 p_input[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "coeffs_300 (Dense)              (None, 1)            9           hidden_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "coeffs_301 (Dense)              (None, 1)            9           hidden_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "contr_310 (Lambda)              (None, 3)            0           coeffs_310[0][0]                 \n",
      "                                                                 p_input[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 20)           0           coeffs_000[0][0]                 \n",
      "                                                                 coeffs_001[0][0]                 \n",
      "                                                                 contr_010[0][0]                  \n",
      "                                                                 coeffs_100[0][0]                 \n",
      "                                                                 coeffs_101[0][0]                 \n",
      "                                                                 contr_110[0][0]                  \n",
      "                                                                 coeffs_200[0][0]                 \n",
      "                                                                 coeffs_201[0][0]                 \n",
      "                                                                 contr_210[0][0]                  \n",
      "                                                                 coeffs_300[0][0]                 \n",
      "                                                                 coeffs_301[0][0]                 \n",
      "                                                                 contr_310[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_48 (Reshape)            (None, 4, 5)         0           concatenate_72[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 6,540\n",
      "Trainable params: 6,540\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def contract(args):\n",
    "    assert len(args) == 2\n",
    "    coeffs = args[0]\n",
    "    channels = args[1]\n",
    "    return tf.reduce_sum(coeffs[...,None,:] * channels, axis=-1)\n",
    "\n",
    "#TODO implement custom layer instead of Dense + Lambda:\n",
    "\n",
    "def build_model(first_sample, pao_basis_size, prim_basis_shells):\n",
    "    \n",
    "    prim_basis_size = sum([(2*l+1)*n for l, n in enumerate(prim_basis_shells)])\n",
    "    num_p_channels = len(first_sample.p_channel_list)\n",
    "    num_d_channels = len(first_sample.d_channel_list)\n",
    "    \n",
    "    # define two sets of inputs\n",
    "    s_input = layers.Input(shape=first_sample.s_channels.shape, name=\"s_input\")\n",
    "    p_input = layers.Input(shape=first_sample.p_channels.shape, name=\"p_input\")\n",
    "    d_input = layers.Input(shape=first_sample.d_channels.shape, name=\"d_input\")\n",
    "    \n",
    "    #TODO: add more hidden layers\n",
    "    scalar_nn_output = layers.Dense(8, name=\"hidden_layer\")(s_input)\n",
    "            \n",
    "    pao_output = []\n",
    "    for i in range(pao_basis_size):\n",
    "        for l, n in enumerate(prim_basis_shells):\n",
    "            for j in range(n):\n",
    "                name = f\"{i}{l}{j}\"\n",
    "                if l == 0:\n",
    "                    s_out = layers.Dense(1, name=\"coeffs_\"+name)(scalar_nn_output)\n",
    "                    pao_output.append(s_out)\n",
    "                elif l == 1:\n",
    "                    p_coeffs = layers.Dense(num_p_channels, name=\"coeffs_\"+name)(scalar_nn_output)\n",
    "                    contract_layer = layers.Lambda(contract, name=\"contr_\"+name)\n",
    "                    p_out = contract_layer([p_coeffs, p_input])\n",
    "                    pao_output.append(p_out)\n",
    "                elif l == 2:\n",
    "                    d_coeffs = layers.Dense(num_d_channels, name=\"coeffs_\"+name)(scalar_nn_output)\n",
    "                    contract_layer = layers.Lambda(contract, name=\"contr_\"+name)\n",
    "                    d_out = contract_layer([d_coeffs, d_input])\n",
    "                    pao_output.append(d_out)\n",
    "                else:\n",
    "                    raise Exception(\"Not implemented\")\n",
    "    \n",
    "    xvec = layers.concatenate(pao_output)\n",
    "    xblock = layers.Reshape((pao_basis_size, prim_basis_size))(xvec) #TODO: maybe transpose?\n",
    "\n",
    "    inputs = [s_input, p_input, d_input]\n",
    "    model = keras.Model(inputs=inputs, outputs=xblock)\n",
    "    model.summary()\n",
    "    return(model)\n",
    "\n",
    "H_model = build_model(H_dataset[0], pao_basis_size, prim_basis_shells['H'])\n",
    "#O_model = build_model(O_dataset[0], pao_basis_size, prim_basis_shells['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "324/324 [==============================] - 0s 706us/sample - loss: 0.0850\n",
      "Epoch 2/100\n",
      "324/324 [==============================] - 0s 111us/sample - loss: 0.0800\n",
      "Epoch 3/100\n",
      "324/324 [==============================] - 0s 124us/sample - loss: 0.0771\n",
      "Epoch 4/100\n",
      "324/324 [==============================] - 0s 123us/sample - loss: 0.0753\n",
      "Epoch 5/100\n",
      "324/324 [==============================] - 0s 130us/sample - loss: 0.0737\n",
      "Epoch 6/100\n",
      "324/324 [==============================] - 0s 123us/sample - loss: 0.0725\n",
      "Epoch 7/100\n",
      "324/324 [==============================] - 0s 123us/sample - loss: 0.0710\n",
      "Epoch 8/100\n",
      "324/324 [==============================] - 0s 131us/sample - loss: 0.0695\n",
      "Epoch 9/100\n",
      "324/324 [==============================] - 0s 128us/sample - loss: 0.0683\n",
      "Epoch 10/100\n",
      "324/324 [==============================] - 0s 93us/sample - loss: 0.0672\n",
      "Epoch 11/100\n",
      "324/324 [==============================] - 0s 83us/sample - loss: 0.0659\n",
      "Epoch 12/100\n",
      "324/324 [==============================] - 0s 114us/sample - loss: 0.0645\n",
      "Epoch 13/100\n",
      "324/324 [==============================] - 0s 86us/sample - loss: 0.0633\n",
      "Epoch 14/100\n",
      "324/324 [==============================] - 0s 82us/sample - loss: 0.0620\n",
      "Epoch 15/100\n",
      "324/324 [==============================] - 0s 99us/sample - loss: 0.0605\n",
      "Epoch 16/100\n",
      "324/324 [==============================] - 0s 87us/sample - loss: 0.0594\n",
      "Epoch 17/100\n",
      "324/324 [==============================] - 0s 90us/sample - loss: 0.0579\n",
      "Epoch 18/100\n",
      "324/324 [==============================] - 0s 87us/sample - loss: 0.0568\n",
      "Epoch 19/100\n",
      "324/324 [==============================] - 0s 87us/sample - loss: 0.0558\n",
      "Epoch 20/100\n",
      "324/324 [==============================] - 0s 92us/sample - loss: 0.0554\n",
      "Epoch 21/100\n",
      "324/324 [==============================] - 0s 89us/sample - loss: 0.0543\n",
      "Epoch 22/100\n",
      "324/324 [==============================] - 0s 86us/sample - loss: 0.0536\n",
      "Epoch 23/100\n",
      "324/324 [==============================] - 0s 80us/sample - loss: 0.0534\n",
      "Epoch 24/100\n",
      "324/324 [==============================] - 0s 89us/sample - loss: 0.0526\n",
      "Epoch 25/100\n",
      "324/324 [==============================] - 0s 89us/sample - loss: 0.0522\n",
      "Epoch 26/100\n",
      "324/324 [==============================] - 0s 88us/sample - loss: 0.0516\n",
      "Epoch 27/100\n",
      "324/324 [==============================] - 0s 86us/sample - loss: 0.0511\n",
      "Epoch 28/100\n",
      "324/324 [==============================] - 0s 94us/sample - loss: 0.0506\n",
      "Epoch 29/100\n",
      "324/324 [==============================] - 0s 91us/sample - loss: 0.0501\n",
      "Epoch 30/100\n",
      "324/324 [==============================] - 0s 84us/sample - loss: 0.0499\n",
      "Epoch 31/100\n",
      "324/324 [==============================] - 0s 89us/sample - loss: 0.0494\n",
      "Epoch 32/100\n",
      "324/324 [==============================] - 0s 88us/sample - loss: 0.0492\n",
      "Epoch 33/100\n",
      "324/324 [==============================] - 0s 90us/sample - loss: 0.0487\n",
      "Epoch 34/100\n",
      "324/324 [==============================] - 0s 90us/sample - loss: 0.0484\n",
      "Epoch 35/100\n",
      "324/324 [==============================] - 0s 88us/sample - loss: 0.0483\n",
      "Epoch 36/100\n",
      "324/324 [==============================] - 0s 96us/sample - loss: 0.0480\n",
      "Epoch 37/100\n",
      "324/324 [==============================] - 0s 90us/sample - loss: 0.0480\n",
      "Epoch 38/100\n",
      "324/324 [==============================] - 0s 90us/sample - loss: 0.0479\n",
      "Epoch 39/100\n",
      "324/324 [==============================] - 0s 88us/sample - loss: 0.0475\n",
      "Epoch 40/100\n",
      "324/324 [==============================] - 0s 90us/sample - loss: 0.0470\n",
      "Epoch 41/100\n",
      "324/324 [==============================] - 0s 95us/sample - loss: 0.0467\n",
      "Epoch 42/100\n",
      "324/324 [==============================] - 0s 88us/sample - loss: 0.0466\n",
      "Epoch 43/100\n",
      "324/324 [==============================] - 0s 91us/sample - loss: 0.0462\n",
      "Epoch 44/100\n",
      "324/324 [==============================] - 0s 85us/sample - loss: 0.0460\n",
      "Epoch 45/100\n",
      "324/324 [==============================] - 0s 118us/sample - loss: 0.0457\n",
      "Epoch 46/100\n",
      "324/324 [==============================] - 0s 85us/sample - loss: 0.0454\n",
      "Epoch 47/100\n",
      "324/324 [==============================] - 0s 86us/sample - loss: 0.0454\n",
      "Epoch 48/100\n",
      "324/324 [==============================] - 0s 99us/sample - loss: 0.0453\n",
      "Epoch 49/100\n",
      "324/324 [==============================] - 0s 89us/sample - loss: 0.0452\n",
      "Epoch 50/100\n",
      "324/324 [==============================] - 0s 88us/sample - loss: 0.0448\n",
      "Epoch 51/100\n",
      "324/324 [==============================] - 0s 90us/sample - loss: 0.0445\n",
      "Epoch 52/100\n",
      "324/324 [==============================] - 0s 84us/sample - loss: 0.0443\n",
      "Epoch 53/100\n",
      "324/324 [==============================] - 0s 101us/sample - loss: 0.0443\n",
      "Epoch 54/100\n",
      "324/324 [==============================] - 0s 85us/sample - loss: 0.0440\n",
      "Epoch 55/100\n",
      "324/324 [==============================] - 0s 88us/sample - loss: 0.0438\n",
      "Epoch 56/100\n",
      "324/324 [==============================] - 0s 94us/sample - loss: 0.0436\n",
      "Epoch 57/100\n",
      "324/324 [==============================] - 0s 88us/sample - loss: 0.0433\n",
      "Epoch 58/100\n",
      "324/324 [==============================] - 0s 97us/sample - loss: 0.0430\n",
      "Epoch 59/100\n",
      "324/324 [==============================] - 0s 80us/sample - loss: 0.0427\n",
      "Epoch 60/100\n",
      "324/324 [==============================] - 0s 84us/sample - loss: 0.0425\n",
      "Epoch 61/100\n",
      "324/324 [==============================] - 0s 84us/sample - loss: 0.0424\n",
      "Epoch 62/100\n",
      "324/324 [==============================] - 0s 85us/sample - loss: 0.0425\n",
      "Epoch 63/100\n",
      "324/324 [==============================] - 0s 81us/sample - loss: 0.0421\n",
      "Epoch 64/100\n",
      "324/324 [==============================] - 0s 94us/sample - loss: 0.0420\n",
      "Epoch 65/100\n",
      "324/324 [==============================] - 0s 87us/sample - loss: 0.0419\n",
      "Epoch 66/100\n",
      "324/324 [==============================] - 0s 96us/sample - loss: 0.0413\n",
      "Epoch 67/100\n",
      "324/324 [==============================] - 0s 87us/sample - loss: 0.0411\n",
      "Epoch 68/100\n",
      "324/324 [==============================] - 0s 96us/sample - loss: 0.0408\n",
      "Epoch 69/100\n",
      "324/324 [==============================] - 0s 90us/sample - loss: 0.0407\n",
      "Epoch 70/100\n",
      "324/324 [==============================] - 0s 86us/sample - loss: 0.0408\n",
      "Epoch 71/100\n",
      "324/324 [==============================] - 0s 84us/sample - loss: 0.0404\n",
      "Epoch 72/100\n",
      "324/324 [==============================] - 0s 86us/sample - loss: 0.0400\n",
      "Epoch 73/100\n",
      "324/324 [==============================] - 0s 102us/sample - loss: 0.0399\n",
      "Epoch 74/100\n",
      "324/324 [==============================] - 0s 93us/sample - loss: 0.0396\n",
      "Epoch 75/100\n",
      "324/324 [==============================] - 0s 95us/sample - loss: 0.0398\n",
      "Epoch 76/100\n",
      "324/324 [==============================] - 0s 80us/sample - loss: 0.0394\n",
      "Epoch 77/100\n",
      "324/324 [==============================] - 0s 81us/sample - loss: 0.0388\n",
      "Epoch 78/100\n",
      "324/324 [==============================] - 0s 100us/sample - loss: 0.0387\n",
      "Epoch 79/100\n",
      "324/324 [==============================] - 0s 77us/sample - loss: 0.0385\n",
      "Epoch 80/100\n",
      "324/324 [==============================] - 0s 93us/sample - loss: 0.0383\n",
      "Epoch 81/100\n",
      "324/324 [==============================] - 0s 87us/sample - loss: 0.0382\n",
      "Epoch 82/100\n",
      "324/324 [==============================] - 0s 94us/sample - loss: 0.0379\n",
      "Epoch 83/100\n",
      "324/324 [==============================] - 0s 85us/sample - loss: 0.0379\n",
      "Epoch 84/100\n",
      "324/324 [==============================] - 0s 89us/sample - loss: 0.0376\n",
      "Epoch 85/100\n",
      "324/324 [==============================] - 0s 85us/sample - loss: 0.0373\n",
      "Epoch 86/100\n",
      "324/324 [==============================] - 0s 95us/sample - loss: 0.0370\n",
      "Epoch 87/100\n",
      "324/324 [==============================] - 0s 82us/sample - loss: 0.0369\n",
      "Epoch 88/100\n",
      "324/324 [==============================] - 0s 89us/sample - loss: 0.0367\n",
      "Epoch 89/100\n",
      "324/324 [==============================] - 0s 80us/sample - loss: 0.0364\n",
      "Epoch 90/100\n",
      "324/324 [==============================] - 0s 81us/sample - loss: 0.0362\n",
      "Epoch 91/100\n",
      "324/324 [==============================] - 0s 94us/sample - loss: 0.0362\n",
      "Epoch 92/100\n",
      "324/324 [==============================] - 0s 84us/sample - loss: 0.0360\n",
      "Epoch 93/100\n",
      "324/324 [==============================] - 0s 86us/sample - loss: 0.0359\n",
      "Epoch 94/100\n",
      "324/324 [==============================] - 0s 99us/sample - loss: 0.0357\n",
      "Epoch 95/100\n",
      "324/324 [==============================] - 0s 85us/sample - loss: 0.0357\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 0s 96us/sample - loss: 0.0353\n",
      "Epoch 97/100\n",
      "324/324 [==============================] - 0s 84us/sample - loss: 0.0356\n",
      "Epoch 98/100\n",
      "324/324 [==============================] - 0s 86us/sample - loss: 0.0350\n",
      "Epoch 99/100\n",
      "324/324 [==============================] - 0s 92us/sample - loss: 0.0347\n",
      "Epoch 100/100\n",
      "324/324 [==============================] - 0s 89us/sample - loss: 0.0346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3c5e5ab438>"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss_function(xblock_true, xblock_pred):\n",
    "    #TODO: This might not be ideal as it implicitly forces the predicted basis vectors to be orthonormal.\n",
    "    projector = tf.matmul(xblock_pred, xblock_pred, transpose_a=True)\n",
    "    residual = xblock_true - tf.matmul(xblock_true, projector)\n",
    "    return tf.reduce_mean(tf.pow(residual, 2))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() #learning_rate=1e-3)\n",
    "H_model.compile(optimizer, loss=loss_function)\n",
    "\n",
    "s_input = np.array([s.s_channels for s in H_dataset], np.float32)\n",
    "p_input = np.array([s.p_channels for s in H_dataset], np.float32)\n",
    "d_input = np.array([s.d_channels for s in H_dataset], np.float32)\n",
    "x_train = [s_input, p_input, d_input]\n",
    "y_train = np.array([s.xblock for s in H_dataset], np.float32)\n",
    "\n",
    "#output = H_model.predict(x_train)\n",
    "\n",
    "H_model.fit(x_train, y_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(H_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
